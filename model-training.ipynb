{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-03-14T00:49:35.194467Z","iopub.status.busy":"2022-03-14T00:49:35.194091Z","iopub.status.idle":"2022-03-14T00:49:35.224127Z","shell.execute_reply":"2022-03-14T00:49:35.223389Z","shell.execute_reply.started":"2022-03-14T00:49:35.194379Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"]},{"cell_type":"markdown","metadata":{},"source":["### Read The Cleaned Data"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-03-14T00:49:35.226142Z","iopub.status.busy":"2022-03-14T00:49:35.225892Z","iopub.status.idle":"2022-03-14T00:49:37.888918Z","shell.execute_reply":"2022-03-14T00:49:37.887926Z","shell.execute_reply.started":"2022-03-14T00:49:35.226115Z"},"trusted":true},"outputs":[],"source":["data=pd.read_csv('dialect_dataset with cleaning text.csv')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-03-14T00:49:37.890434Z","iopub.status.busy":"2022-03-14T00:49:37.890149Z","iopub.status.idle":"2022-03-14T00:49:37.912220Z","shell.execute_reply":"2022-03-14T00:49:37.911340Z","shell.execute_reply.started":"2022-03-14T00:49:37.890400Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>dialect</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1175358310087892992</td>\n","      <td>IQ</td>\n","      <td>لكن بالنهاية ينتفض يغير</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1175416117793349632</td>\n","      <td>IQ</td>\n","      <td>يعني هذا محسوب على البشر حيونه ووحشيه وتطلبون...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1175450108898565888</td>\n","      <td>IQ</td>\n","      <td>مبين من كلامه خليجي</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1175471073770573824</td>\n","      <td>IQ</td>\n","      <td>يسلملي مرورك وروحك الحلوه</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1175496913145217024</td>\n","      <td>IQ</td>\n","      <td>وين هل الغيبه اخ محمد</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    id dialect  \\\n","0  1175358310087892992      IQ   \n","1  1175416117793349632      IQ   \n","2  1175450108898565888      IQ   \n","3  1175471073770573824      IQ   \n","4  1175496913145217024      IQ   \n","\n","                                                text  \n","0                           لكن بالنهاية ينتفض يغير   \n","1   يعني هذا محسوب على البشر حيونه ووحشيه وتطلبون...  \n","2                                مبين من كلامه خليجي  \n","3                          يسلملي مرورك وروحك الحلوه  \n","4                             وين هل الغيبه اخ محمد   "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","metadata":{},"source":["#### Drop Null Values"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-03-14T00:49:37.914639Z","iopub.status.busy":"2022-03-14T00:49:37.914175Z","iopub.status.idle":"2022-03-14T00:49:38.064077Z","shell.execute_reply":"2022-03-14T00:49:38.063155Z","shell.execute_reply.started":"2022-03-14T00:49:37.914596Z"},"trusted":true},"outputs":[],"source":["data=data.dropna()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-03-14T00:49:38.066336Z","iopub.status.busy":"2022-03-14T00:49:38.066072Z","iopub.status.idle":"2022-03-14T00:49:38.178294Z","shell.execute_reply":"2022-03-14T00:49:38.177373Z","shell.execute_reply.started":"2022-03-14T00:49:38.066305Z"},"trusted":true},"outputs":[{"data":{"text/plain":["id         0\n","dialect    0\n","text       0\n","dtype: int64"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data.isna().sum()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-03-14T00:49:38.180048Z","iopub.status.busy":"2022-03-14T00:49:38.179749Z","iopub.status.idle":"2022-03-14T00:49:38.186853Z","shell.execute_reply":"2022-03-14T00:49:38.186102Z","shell.execute_reply.started":"2022-03-14T00:49:38.180017Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(458196, 3)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data.shape"]},{"cell_type":"markdown","metadata":{},"source":["#### Spliting the Data to Train and Test\n","* Train = 80% of Data\n","* Test = 20% of Data"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-03-14T00:49:38.188422Z","iopub.status.busy":"2022-03-14T00:49:38.188079Z","iopub.status.idle":"2022-03-14T00:49:40.292310Z","shell.execute_reply":"2022-03-14T00:49:40.291289Z","shell.execute_reply.started":"2022-03-14T00:49:38.188387Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split,GridSearchCV\n","feature= data['text']\n","target=data['dialect']\n","x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, stratify=target, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["#### Import Arabic Stopwords from NLTK"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-03-14T00:50:08.719572Z","iopub.status.busy":"2022-03-14T00:50:08.719212Z","iopub.status.idle":"2022-03-14T00:50:08.746693Z","shell.execute_reply":"2022-03-14T00:50:08.745910Z","shell.execute_reply.started":"2022-03-14T00:50:08.719539Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Unzipping corpora\\stopwords.zip.\n"]}],"source":["import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","arabic= stopwords.words('arabic')\n"]},{"cell_type":"markdown","metadata":{},"source":["### Build Pipeline model\n","use TFIDF vectorizer with character analyzer and remove arabic stop words\n","\n","then use logistic regression model to classify text"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-03-14T00:50:11.053958Z","iopub.status.busy":"2022-03-14T00:50:11.053136Z","iopub.status.idle":"2022-03-14T02:20:00.930162Z","shell.execute_reply":"2022-03-14T02:20:00.929350Z","shell.execute_reply.started":"2022-03-14T00:50:11.053922Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Pipeline(steps=[('tfidfvectorizer',\n","                 TfidfVectorizer(analyzer='char', max_df=0.998, min_df=8e-06,\n","                                 ngram_range=(3, 5),\n","                                 stop_words=['إذ', 'إذا', 'إذما', 'إذن', 'أف',\n","                                             'أقل', 'أكثر', 'ألا', 'إلا',\n","                                             'التي', 'الذي', 'الذين', 'اللاتي',\n","                                             'اللائي', 'اللتان', 'اللتيا',\n","                                             'اللتين', 'اللذان', 'اللذين',\n","                                             'اللواتي', 'إلى', 'إليك', 'إليكم',\n","                                             'إليكما', 'إليكن', 'أم', 'أما',\n","                                             'أما', 'إما', 'أن', ...])),\n","                ('logisticregression', LogisticRegression(max_iter=7000))])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.svm import SVC\n","from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import LinearSVC\n","from nltk.corpus import stopwords\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","\n","\n","vectorizer = TfidfVectorizer(analyzer='char',stop_words=arabic , ngram_range=(3, 5), min_df=.000008, max_df=.998)\n","# vectorizer= CountVectorizer(analyzer='char',stop_words=arabic , ngram_range=(4, 6))\n","model = LogisticRegression(max_iter=7000)\n","pipe = make_pipeline(vectorizer, model)\n","pipe.fit(x_train, y_train)\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Prediction\n","Predict test data and print the accuracy"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-03-14T02:20:00.932110Z","iopub.status.busy":"2022-03-14T02:20:00.931838Z","iopub.status.idle":"2022-03-14T02:20:24.298817Z","shell.execute_reply":"2022-03-14T02:20:24.297757Z","shell.execute_reply.started":"2022-03-14T02:20:00.932080Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy score is 0.56\n"]}],"source":["from sklearn.metrics import confusion_matrix,accuracy_score\n","prediction = pipe.predict(x_test)\n","print(f\"Accuracy score is {accuracy_score(y_test, prediction):.2f}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Custom Test data\n","use another test data to predict dialect  "]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-03-14T02:27:24.307862Z","iopub.status.busy":"2022-03-14T02:27:24.307235Z","iopub.status.idle":"2022-03-14T02:27:24.356967Z","shell.execute_reply":"2022-03-14T02:27:24.356090Z","shell.execute_reply.started":"2022-03-14T02:27:24.307812Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['EG']\n"]}],"source":["input=['سلام يا صاحبي']\n","pre=pipe.predict(input)\n","print(pre)"]},{"cell_type":"markdown","metadata":{},"source":["### Save Model to Jason file "]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# model_json5 = pipe.to_json()\n","# with open(\"./model5.json\", \"w\") as json_file:\n","#     json_file.write(model_json5)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import pickle\n","pipeline_pkl=pickle.dump(pipe,open('pipeline.pkl', 'wb'))"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["import pickle\n","vectorizer_pkl=pickle.dump(vectorizer,open('vectorizer.pkl', 'wb'))"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["import pickle\n","model_pkl=pickle.dump(model,open('model.pkl', 'wb'))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":4}
